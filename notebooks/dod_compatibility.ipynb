{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPATIBILITY EXAMPLE\n",
    "\n",
    "In this notebook we provide an example to show how the `LocalBasis` class is compatible with both the `weighted_POD` and `DOD` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlroms import*\n",
    "from dlroms.roms import*\n",
    "import dlroms.fespaces as fe\n",
    "\n",
    "import numpy as np\n",
    "from numpy import pi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../code')\n",
    "\n",
    "from PODlib import *\n",
    "from variabilitylib import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "dataset = np.load(\"../data/nstokes_data.npz\")\n",
    "mu, u = dv.tensor(dataset['mu']), dv.tensor(dataset['u'])\n",
    "\n",
    "ndata, ntimes, nh = u.shape\n",
    "p = mu.shape[-1]\n",
    "\n",
    "# MESH\n",
    "mesh = fe.loadmesh(\"../data/nstokes_mesh.xml\")\n",
    "Vh = fe.space(mesh, 'CG', 2)\n",
    "\n",
    "# REPARAMETRIZATION\n",
    "epsilon = np.power(10, mu[:, 0])\n",
    "rho = mu[:, 1]\n",
    "eta = epsilon / rho\n",
    "\n",
    "mu[:, 0] = (1/rho)\n",
    "mu[:, 1] = eta\n",
    "\n",
    "# RESHAPE TO MAKE TIME A PARAMETER\n",
    "mut = dv.zeros(ndata, ntimes, p+1)\n",
    "times = dv.tensor(np.linspace(0, 3.5, ntimes))\n",
    "for i in range(ndata):\n",
    "    mut[i,:,:2] = mu[i]\n",
    "    mut[i,:, 2] = times\n",
    "\n",
    "u = u.reshape(-1, nh)\n",
    "mut = mut.reshape(-1, p+1)\n",
    "\n",
    "# NUMBER OF TRAINING DATA\n",
    "ntrain = 31*ntimes\n",
    "\n",
    "# SET SEED FOR MONTE CARLO ESTIMATES\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambient space setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nA = 100\n",
    "V, svalues = POD(u[:ntrain], k = nA)\n",
    "A = gramschmidt(V.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "uA = projectdown(A, u).squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOD class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DOD(DFNN):\n",
    "    def __init__(self, root, branch, n = 1, A = None, trainable = True, qr = QRgramschmidt):\n",
    "        super(DOD, self).__init__(root, branch**n, n = n, A = A, trainable = trainable, qr = qr)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.qr(super(DOD, self).forward(x).transpose(1,2)).transpose(1,2)\n",
    "        return out if self.trainable else out.matmul(self.A)\n",
    "    \n",
    "    def innerdod(self, x):\n",
    "        return self.qr(super(DOD, self).forward(x).transpose(1,2)).transpose(1,2)\n",
    "    \n",
    "    def freeze(self):\n",
    "        super(DOD, self).freeze()\n",
    "        self.trainable = False\n",
    "        \n",
    "    def basis(self, mu):\n",
    "        if(self.trainable):\n",
    "            raise RuntimeError(\"Cannot produce a hierarchically sorted basis during training. Please freeze the model first.\")\n",
    "        return POD(self.solve(mu), self.n, inner = self.inner)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOD neural network definition\n",
    "\n",
    "We consider the case where $\\mu = (1/\\rho,t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlroms.dnns import Reshape\n",
    "from dlroms.dnns import Fourier\n",
    "\n",
    "class Separated(ROM):\n",
    "    def forward(self, x):\n",
    "        return ((self[0](self.geom(x)))*(self[1](self.phys(x)))).sum(axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbad = 2\n",
    "pgood = (p+1) - pbad\n",
    "mu_bad = mut[:, [0,2]]\n",
    "\n",
    "# We define the architectures for the seed and the roots neural network\n",
    "arch1 = Dense(1, 50) + Dense(50, 8*12) + Reshape(8, 12)\n",
    "arch2 = Fourier(4) + Dense(9, 30) + Dense(30, 8*12) + Reshape(8, 12)\n",
    "psi = Separated(arch1, arch2, geom = lambda m: m[:, [0]], phys = lambda m: m[:, [1]])\n",
    "\n",
    "root = Dense(8, 50) + Dense(50, 50) + Dense(50, nA, activation = None)\n",
    "\n",
    "dod = DOD(psi, root, n = 4, A = A)\n",
    "dod.He()\n",
    "\n",
    "# Error and loss\n",
    "def DODerror(utrue, Vpred):\n",
    "  upred = project(Vpred, utrue, orth = False)\n",
    "  return (euclidean(utrue-upred).reshape(-1, ntimes).sum(axis = -1)/\n",
    "          euclidean(utrue).reshape(-1, ntimes).sum(axis = -1)        ).mean()\n",
    "\n",
    "def DODloss(utrue, Vpred):\n",
    "  upred = project(Vpred, utrue, orth = False)\n",
    "  return (euclidean(utrue-upred, squared = True).reshape(-1, ntimes).sum(axis = -1)).mean()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the DOD object has been defined, we can load an already trained neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dod.load(\"../results/Test_DOD.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `weighted_POD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4 # we take the same number of basis the DOD has been trained for\n",
    "lambda_penalty = 5e-1\n",
    "\n",
    "w_POD = weighted_POD(A=A,\n",
    "                     U=torch.t(uA[:ntrain,:]),\n",
    "                     theta_full=torch.t(mut[:ntrain,:]),\n",
    "                     n_basis=n,\n",
    "                     omega_func=lambda theta, theta_i: omega_weights(theta, theta_i, lambda_penalty=lambda_penalty))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `LocalBasis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mut = mut.max(axis = 0).values\n",
    "min_mut = mut.min(axis = 0).values\n",
    "\n",
    "def scaling(theta):\n",
    "    return theta * (max_mut-min_mut) + min_mut\n",
    "\n",
    "POD_var = LocalBasis(q=p+1,\n",
    "                     module=w_POD, \n",
    "                     p_prime_index_list=np.arange(p+1), \n",
    "                     scaling=scaling)\n",
    "\n",
    "DOD_var = LocalBasis(q=p+1,\n",
    "                     module=dod, \n",
    "                     p_prime_index_list=[0,2], # the bad parameters are the same the DOD has been trained for \n",
    "                     scaling=scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check compatibility\n",
    "\n",
    "We can look at the following:\n",
    "\n",
    "* the size of an output space;\n",
    "* what happens when checking the K score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of the space\n",
    "\n",
    "Define a random $\\hat{\\theta}$ in $[0,1]^q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "theta_hat = torch.rand(pbad+pgood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected size for both is a tensor of size $n \\times N_A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of the output space for POD_var:\\t\", POD_var(theta_hat).size())\n",
    "print(\"Size of the output space for DOD_var:\\t\", DOD_var(theta_hat).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K score\n",
    "\n",
    "When computing the K score, we are measuring how adaptive the `module` is against all the parameters.\n",
    "If the direction we compute the score is one of the directions the `DOD` has been trained for, both object will output a value different from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POD_K = POD_var.K_j_sup(0, theta_hat)\n",
    "print(f\"The value of the K score for 1/ρ computed by POD_var:\\t{POD_K:.6e}\")\n",
    "DOD_K = DOD_var.K_j_sup(0, theta_hat)\n",
    "print(f\"The value of the K score for 1/ρ computed by DOD_var:\\t{DOD_K:.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If instead the corresponding parameter is not one the `DOD` has not been trained for (in this case $\\eta$), its score will be automatically assigned to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POD_K = POD_var.K_j_sup(1, theta_hat)\n",
    "print(f\"The value of the K score for η computed by POD_var:\\t{POD_K:.6e}\")\n",
    "DOD_K = DOD_var.K_j_sup(1, theta_hat)\n",
    "print(f\"The value of the K score for η computed by DOD_var:\\t{DOD_K:.6e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fenics-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
